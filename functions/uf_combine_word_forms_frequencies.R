# ..............................................................................
#
# uf_combine_word_forms_frequencies.R   
#
# Функция пересчитывает частоты английский слов, совмещая простые словоформы
#
# Автор: Суязова (Аксюк) Светлана s.a.aksuk@gmail.com
# 
# Версия: 1.0 (07 Aug 2025)
#
# ******************************************************************************
# Аргументы:
#  * data         data.table    таблица со словами и их частотами
#  * df_endings   data.frame    таблица с окончаниями для анализа:
#                                каждая строка - пара окончаний, которые при
#                                совпадении основ считаются одним и тем же 
#                                словом
#
# Возвращаемое значение: таблица df с обновлёнными частотами. В каждой паре
#   (основа + окончание) удаляем форму со вторым окончанием, а форме с первым
#   приписываем их суммарную частоту.
# 
# Создаёт / модифицирует файлы: 
#  нет
#
# ******************************************************************************
# Зависимости:
#  нет
#
# ******************************************************************************
# Примечание:
#  При работе с окончаниями важно учитывать алфавитную сортировку: основа слова 
#  с окончанием pattern_1 идёт сразу перед основой слова с окончанием pattern_2, 
#  и все варианты окончаний тоже упорядочены по алфавиту.
#
# ..............................................................................

uf_combine_word_forms_frequencies <- function(data, df_endings) {
    
    # цикл по вариантам окончаний
    for (i in 1:nrow(df_endings)) {
        
        # print(df_endings[i, ])
        
        # поправка на удалённые в цикле строки
        n <- dim(data)[1]
        
        # ищем окончания точно как в шаблонах
        index_p1 <- grep(paste0('(.*)', df_endings$pattern_1[i], '$'), 
                         data$word[-1]) + 1
        index_p2 <- grep(paste0('(.*)', df_endings$pattern_2[i], '$'), 
                         data$word[-n])
        
        # искомые пары идут строго друг за другом, поэтому нужны только
        #  последовательные индексы
        index <- intersect(index_p1, index_p2 - 1)
        
        # это основы первых слов из пары
        compare_1 <- gsub(paste0('(.*)', df_endings$pattern_1[i], '$'), 
                          '\\1', data$word[index])
        # это основы вторых слов из пары
        compare_2 <- gsub(paste0('(.*)', df_endings$pattern_2[i], '$'), 
                          '\\1', data$word[index + 1])
        
        # # смотрим, с какими парами работаем
        # srch <- paste0('^', intersect(compare_1, compare_2),
        #                '(', df_endings$pattern_1[i], '|', 
        #                df_endings$pattern_2[i], ')$')
        # sapply(srch, function(x){
        #     grepl(x, data$word) %>% unlist %>% unname
        # }) %>% apply(1, sum) %>% as.logical %>% filter(.data = data) %>% print
        
        # проверяем, чтобы у вторых слов из пар была точно такая же основа
        index <- index[compare_1 %>% sapply(function(x){x == compare_2}) %>% 
                           unname %>% unlist %>% apply(1, sum) %>% as.logical]
        
        # совмещаем частоты
        if (df_endings$drop_pattern_2[i]) {
            
            # суммарную частоту приписываем первому слову из пары
            data[index, 'freq'] <- data[index, 'freq'] + data[index + 1, 'freq']
            
            # второе слово удаляем
            data <- data[-(index + 1), ]
            
        } else {
            
            # суммарную частоту приписываем второму слову из пары
            data[index + 1, 'freq'] <- 
                data[index + 1, 'freq'] + data[index, 'freq']
            
            # первое слово удаляем
            data <- data[-(index), ]
        }
        
        # # проверяем, что осталось от основ
        # sapply(srch, function(x){
        #     grepl(x, data$word) %>% unlist %>% unname
        # }) %>% apply(1, sum) %>% as.logical %>% filter(.data = data) %>% print
    }
    
    return(data)
}
